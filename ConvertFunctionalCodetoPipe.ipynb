{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvertFunctionalCodetoPipe.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMgZEih7Yfcg5rk4kNwFZh9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MingzheHu-Duke/Note_to_product_HousePricePrediction/blob/main/ConvertFunctionalCodetoPipe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwZbrMz_Ps7o"
      },
      "source": [
        "# Part A: Basic Pipeline codes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUEStQMvQC8d",
        "outputId": "0416381f-1a33-4c55-8bf2-5b62149171ce"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"/content/sonar.all-data.csv\")\n",
        "\n",
        "\n",
        "# Separate training and validation dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "X = data.values[:, 0:60]\n",
        "Y = data.values[:, 60]\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Build Pipelines - Import neccessary libraries\n",
        "\n",
        "\n",
        "# 1. Single pipeline for prediction\n",
        "pipe = Pipeline([\n",
        "                 (\"LR\", LogisticRegression())\n",
        "])\n",
        "\n",
        "pipe.fit(X_train, Y_train)\n",
        "pred = pipe.predict(X_val)\n",
        "print(accuracy_score(Y_val, pred))\n",
        "\n",
        "\n",
        "# 2 Single Pipeline with data scaling\n",
        "pipe = Pipeline([\n",
        "                 (\"Scaler\", StandardScaler()),\n",
        "                 (\"LR\", LogisticRegression())\n",
        "])\n",
        "pipe.fit(X_train, Y_train)\n",
        "pred = pipe.predict(X_val)\n",
        "print(accuracy_score(Y_val, pred))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7619047619047619\n",
            "0.7857142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gT4uEAaXWZJ"
      },
      "source": [
        "# Preprocessor.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zvRgJVUXa8X"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import config\n",
        "\n",
        "\n",
        "# Numerical Imputer\n",
        "class NumericalImputer(BaseEstimator, TransformerMixin):\n",
        "  \"\"\"Numerical Data Missing Value Imputer\"\"\"\n",
        "  def __init__(self, variables=None):\n",
        "    self.variables = variables\n",
        "\n",
        "  def fit(self, X, y=None):\n",
        "    self.imputer_dict_ = {}\n",
        "    for feature in self.variables:\n",
        "      self.imputer_dict_[feature] = X[feature].mode()[0]\n",
        "    return self\n",
        "\n",
        "  def transform(self, X):\n",
        "    X = X.copy()\n",
        "    for feature in self.variables:\n",
        "      X[feature].fillna(self.imputer_dict_[feature], inplace=True)\n",
        "    return X\n",
        "\n",
        "\n",
        "#Categorical Imputer\n",
        "# def categorical_imputer(_data, CATEGORICAL_FEATURES):\n",
        "#     for var in CATEGORICAL_FEATURES:\n",
        "#         _data[var].fillna(_data[var].mode()[0], inplace=True)   \n",
        "#     return _data\n",
        "class CategoricalImputer(BaseEstimator,TransformerMixin):\n",
        "    def __init__(self, variables=None):\n",
        "        self.variables = variables\n",
        "    \n",
        "    def fit(self, X,y=None):\n",
        "        self.imputer_dict_={}\n",
        "        for feature in self.variables:\n",
        "            self.imputer_dict_[feature] = X[feature].mode()[0]\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        X=X.copy()\n",
        "        for feature in self.variables:\n",
        "            X[feature].fillna(self.imputer_dict_[feature],inplace=True)\n",
        "        return X\n",
        "\n",
        "\n",
        "\n",
        "#Rare label Categorical Encoder\n",
        "# def rare_label_cat_imputer(_data, FEATURES_TO_ENCODE):\n",
        "#     encoder_dict_ = {}\n",
        "#     tol=0.05\n",
        "    \n",
        "#     for var in FEATURES_TO_ENCODE:\n",
        "#         # the encoder will learn the most frequent categories\n",
        "#         t = pd.Series(_data[var].value_counts() / np.float(len(_data)))\n",
        "#         # frequent labels:\n",
        "#         encoder_dict_[var] = list(t[t >= tol].index)\n",
        "        \n",
        "#     for var in FEATURES_TO_ENCODE:\n",
        "#         _data[var] = np.where(_data[var].isin(\n",
        "#                     encoder_dict_[var]), _data[var], 'Rare')\n",
        "    \n",
        "#     return _data\n",
        "\n",
        "class RareLabelCategoricalImputer(BaseEstimator,TransformerMixin):\n",
        "    def __init__(self, tol=0.05, variables=None):\n",
        "        self.tol=tol\n",
        "        self.variables=variables\n",
        "    \n",
        "    def fit(self, X, y=None):\n",
        "        self.encoder_dict_={}\n",
        "        for var in self.variables:\n",
        "            # the encoder will learn the most frequent categories\n",
        "            t = pd.Series(X[var].value_counts() / np.float(len(X)))\n",
        "            # frequent labels:\n",
        "            self.encoder_dict_[var] = list(t[t >= self.tol].index)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X=X.copy()\n",
        "        for feature in self.variables:\n",
        "            X[feature] = np.where(X[feature].isin(self.encoder_dict_[feature]), X[feature], 'Rare')\n",
        "        return X\n",
        "\n",
        "\n",
        "\n",
        "#Categorical Encoder\n",
        "# def categorical_encoder(_data, FEATURES_TO_ENCODE):\n",
        "#     encoder_dict_ ={}\n",
        "#     for var in FEATURES_TO_ENCODE:\n",
        "#         t = _data[var].value_counts().sort_values(ascending=True).index \n",
        "#         encoder_dict_[var] = {k:i for i,k in enumerate(t,0)}\n",
        "        \n",
        "#     ## Mapping using the encoder dictionary\n",
        "#     for var in FEATURES_TO_ENCODE:\n",
        "#         _data[var] = _data[var].map(encoder_dict_[var])\n",
        "    \n",
        "#     return _data\n",
        "class CategoricalEncoder(BaseEstimator,TransformerMixin):\n",
        "    def __init__(self, variables=None):\n",
        "        self.variables=variables\n",
        "    \n",
        "    def fit(self, X,y):\n",
        "        self.encoder_dict_ = {}\n",
        "        for var in self.variables:\n",
        "            t = X[var].value_counts().sort_values(ascending=True).index \n",
        "            self.encoder_dict_[var] = {k:i for i,k in enumerate(t,0)}\n",
        "        return self\n",
        "    \n",
        "    def transform(self,X):\n",
        "        X=X.copy()\n",
        "        ##This part assumes that categorical encoder does not intorduce and NANs\n",
        "        ##In that case, a check needs to be done and code should break\n",
        "        for feature in self.variables:\n",
        "            X[feature] = X[feature].map(self.encoder_dict_[feature])\n",
        "        return X\n",
        "\n",
        "# #Temporal Variables\n",
        "# def temporal_transform(_data, TEMPORAL_FEATURES, TEMPORAL_COMPARISON):\n",
        "#     for var in TEMPORAL_FEATURES:\n",
        "#         _data[var] = _data[var]-_data[TEMPORAL_COMPARISON]\n",
        "    \n",
        "#     return _data\n",
        "\n",
        "class TemporalVariableEstimator(BaseEstimator,TransformerMixin):\n",
        "    def __init__(self, variables=None, reference_variable = None):\n",
        "        self.variables=variables\n",
        "        self.reference_variable = reference_variable\n",
        "    \n",
        "    def fit(self, X,y=None):\n",
        "        #No need to put anything, needed for Sklearn Pipeline\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        X=X.copy()\n",
        "        for var in self.variables:\n",
        "            X[var] = X[var]-X[self.reference_variable]\n",
        "        return X \n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "# # Log Transformations\n",
        "# def log_transform(_data, LOG_FEATURES):\n",
        "#     for var in LOG_FEATURES:\n",
        "#         _data[var] = np.log(_data[var])\n",
        "#     return _data\n",
        "\n",
        "class LogTransformation(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, variables=None):\n",
        "        self.variables = variables\n",
        "    \n",
        "    def fit(self, X,y):\n",
        "        return self\n",
        "\n",
        "    ### Need to check in advance if the features are all non negative >0\n",
        "    ### If yes, needs to be transformed properly\n",
        "    def transform(self,X):\n",
        "        X=X.copy()\n",
        "        for var in self.variables:\n",
        "            X[var] = np.log(X[var])\n",
        "        return X\n",
        "\n",
        "\n",
        "# # Drop Features\n",
        "# def drop_features(_data, DROP_FEATURES):    \n",
        "#     _data.drop(DROP_FEATURES, axis=1, inplace=True)\n",
        "#     return _data\n",
        "    \n",
        "class DropFeatures(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, variables_to_drop=None):\n",
        "        self.variables_to_drop = variables_to_drop\n",
        "    \n",
        "    def fit(self, X,y=None):\n",
        "        return self \n",
        "    \n",
        "    def transform(self, X):\n",
        "        X=X.copy()\n",
        "        X= X.drop(self.variables_to_drop, axis=1)\n",
        "        return  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOmmKXpEbLwg"
      },
      "source": [
        "# pipeline.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uP2sc4rbkNb"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import preprocessing as pp\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "import configparser\n",
        "\n",
        "price_pipe = Pipeline([\n",
        "        (\"Numercial Imputer\", pp.NumericalImputer(variables=config.NUMERICAL_FEATURES)),\n",
        "        ('Categorical Imputer', pp.CategoricalImputer(variables = config.CATEGORICAL_FEATURES)),\n",
        "        ('Temporal Features', pp.TemporalVariableEstimator(variables = config.TEMPORAL_FEATURES, \n",
        "        reference_variable=config.TEMPORAL_COMPARISON)),\n",
        "        ('Rare Label Encoder', pp.RareLabelCategoricalImputer(variables = config.FEATURES_TO_ENCODE)),\n",
        "        ('Categorical Encoder', pp.CategoricalEncoder(variables=config.FEATURES_TO_ENCODE)),\n",
        "        ('Log Transform', pp.LogTransformation(variables = config.LOG_FEATURES)),\n",
        "        ('Drop Features', pp.DropFeatures(variables_to_drop=config.DROP_FEATURES)),\n",
        "        (\"Scaler Transform\", MinMaxScaler()),\n",
        "        (\"Linear Model\", Lasso(alpha=0.005, random_state=42))\n",
        "\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_lzfJTedroT"
      },
      "source": [
        "# MainCode.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYeQ7295dwuC"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import config\n",
        "from data_management import load_dataset\n",
        "import preprocessor as pp\n",
        "import pipelinee\n",
        "\n",
        "\n",
        "train = load_dataset(config.TRAIN_FILE)\n",
        "test = load_dataset(config.TEST_FILE)\n",
        "\n",
        "\n",
        "# Seperating Saleprice in Y\n",
        "y = train[config.TARGET]\n",
        "train.drop([config.TARGET],axis=1, inplce=True)\n",
        "\n",
        "\n",
        "pipeline.price_pipe.fit(train[config.KEEP], y)\n",
        "pipeline.price_pipe..predict(test[config.KEEP])\n",
        "\n",
        "\n",
        "print(\"Top 10 predictions: \", pred[1:10])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}